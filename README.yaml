---
#
# This is the canonical configuration for the `README.md`
# Run `make readme` to rebuild the `README.md`
#

# Name of this project
name: Terraform AWS EKS

# License of this project
license: "MIT"

# Canonical GitHub repo
github_repo: clouddrove/terraform-aws-eks

# Badges to display
badges:
  - name: "Terraform"
    image: "https://img.shields.io/badge/Terraform-v0.13-green"
    url: "https://www.terraform.io"
  - name: "Licence"
    image: "https://img.shields.io/badge/License-MIT-blue.svg"
    url: "LICENSE.md"

# Prerequesties to display
prerequesties:
  - name: "Kubectl"
    url: "https://kubernetes.io/docs/tasks/tools/install-kubectl/"
  - name: "AWS IAM Authenticator"
    url: "https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html"


#  description of this project
description: |-
  Terraform module will be created Autoscaling, Workers, EKS, Node Groups.

# extra content
include:
  - "terraform.md"

# How to use this project
usage : |-
  ### Sample example
  Here is an example of how you can use this module in your inventory structure:
  ```hcl
  module "eks-cluster" {
       source      = "clouddrove/eks/aws"
       version     = "0.15.0"

       ## Tags
       name        = "eks"
       environment = "test"
       label_order = ["environment", "application", "name"]
       enabled     = true

       ## Network
       vpc_id                              = module.vpc.vpc_id
       eks_subnet_ids                      = module.subnets.public_subnet_id
       worker_subnet_ids                   = module.subnets.private_subnet_id
       allowed_security_groups_cluster     = []
       allowed_security_groups_workers     = []
       additional_security_group_ids       = [module.ssh.security_group_ids]
       endpoint_private_access             = false
       endpoint_public_access              = true
       public_access_cidrs                 = ["0.0.0.0/0"]
       cluster_encryption_config_resources = ["secrets"]
       associate_public_ip_address         = false
       key_name                            = module.keypair.name

       ## volume_size
       volume_size = 20

       ## ondemand
       ondemand_enabled          = true
       ondemand_instance_type    = ["t3.small", "t3.medium", "t3.small"]
       ondemand_max_size         = [1, 0, 0]
       ondemand_min_size         = [1, 0, 0]
       ondemand_desired_capacity = [1, 0, 0]

       ondemand_schedule_enabled            = true
       ondemand_schedule_max_size_scaleup   = [0, 0, 0]
       ondemand_schedule_desired_scaleup    = [0, 0, 0]
       ondemand_schedule_min_size_scaleup   = [0, 0, 0]
       ondemand_schedule_min_size_scaledown = [0, 0, 0]
       ondemand_schedule_max_size_scaledown = [0, 0, 0]
       ondemand_schedule_desired_scale_down = [0, 0, 0]


       ## Spot
       spot_enabled          = true
       spot_instance_type    = ["t3.small", "t3.medium", "t3.small"]
       spot_max_size         = [1, 0, 0]
       spot_min_size         = [1, 0, 0]
       spot_desired_capacity = [1, 0, 0]
       max_price             = ["0.20", "0.20", "0.20"]

       spot_schedule_enabled            = true
       spot_schedule_min_size_scaledown = [0, 0, 0]
       spot_schedule_max_size_scaledown = [0, 0, 0]
       spot_schedule_desired_scale_down = [0, 0, 0]
       spot_schedule_desired_scaleup    = [0, 0, 0]
       spot_schedule_max_size_scaleup   = [0, 0, 0]
       spot_schedule_min_size_scaleup   = [0, 0, 0]

       ## Schedule time
       scheduler_down = "0 19 * * MON-FRI" #diffrent
       scheduler_up   = "0 6 * * MON-FRI"

       #node_group
       node_group_enabled              = true
       node_group_name                 = ["tools", "api"]
       node_group_instance_types       = ["t3.small", "t3.medium"]
       node_group_min_size             = [1, 1]
       node_group_desired_size         = [1, 1]
       node_group_max_size             = [2, 2]
       node_group_volume_size          = 20
       before_cluster_joining_userdata = ""
       node_group_capacity_type        = "ON_DEMAND"node_groups = {
        tools = {
          node_group_name           = "autoscale"
          subnet_ids                = module.subnets.private_subnet_id
          ami_type                  = "AL2_x86_64"
          node_group_volume_size    = 100
          node_group_instance_types = ["t3.large"]
          kubernetes_labels         = {}
          kubernetes_version        = "1.20"
          node_group_desired_size   = 1
          node_group_max_size       = 1
          node_group_min_size       = 1
          node_group_capacity_type  = "ON_DEMAND"
          node_group_volume_type    = "gp2"
        }
       }

       ## Cluster
       wait_for_capacity_timeout = "15m"
       apply_config_map_aws_auth = true
       kubernetes_version        = "1.18"
       map_additional_iam_users = [
         {
           userarn  = "arn:aws:iam::924144197303:user/rishabh@clouddrove.com"
           username = "rishabh@clouddrove.com"
           groups   = ["system:masters"]
         },
         {
           userarn  = "arn:aws:iam::924144197303:user/nikita@clouddrove.com"
           username = "nikita@clouddrove.com"
           groups   = ["system:masters"]
         }

       ]


       ## Health Checks
       cpu_utilization_high_threshold_percent = 80
       cpu_utilization_low_threshold_percent  = 20
       health_check_type                      = "EC2"

       ## EBS Encryption
       ebs_encryption = true

       ## logs
       enabled_cluster_log_types = ["api", "audit", "authenticator", "controllerManager", "scheduler"]
      }
   ```
